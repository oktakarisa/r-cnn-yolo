{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN and YOLOv3 Object Detection Assignment\n",
    "\n",
    "This notebook contains the comprehensive analysis and implementation of both Faster R-CNN and YOLOv3 object detection models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Faster R-CNN - Problem 2: Code Analysis\n",
    "\n",
    "### Important Components of Faster R-CNN Implementation:\n",
    "\n",
    "#### **Region Proposal Network (RPN)**\n",
    "- **Location**: `data/faster_rcnn/model/resnet.py` - function `rpn(base_layers, num_anchors)`\n",
    "- **Implementation**: The RPN is implemented as a convolutional layer that slides over the feature map and generates region proposals\n",
    "- **Key Lines**:\n",
    "  ```python\n",
    "  def rpn(base_layers,num_anchors):\n",
    "      x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
    "      x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
    "  ```\n",
    "\n",
    "#### **ROI Pooling Implementation**\n",
    "- **Location**: `data/faster_rcnn/model/RoiPoolingConv.py`\n",
    "\n",
    "ROI Pooling is implemented using a custom Keras layer.\n",
    "\n",
    "**Important Features:**\n",
    "\n",
    "   - Manages the image data formats channels_first and channels_last.\n",
    "\n",
    "   - TensorFlow resize operations are used for effective pooling.\n",
    "\n",
    "   - Applying max pooling and converting ROI coordinates to cropped regions\n",
    "\n",
    "#### **Backbone Network (ResNet)**\n",
    "- **Location**: `data/faster_rcnn/model/resnet.py`\n",
    "\n",
    "ResNet-50 serves as the primary feature extractor in the implementation.\n",
    "\n",
    "**Important Functions:**\n",
    "\n",
    "   - `nn_base()`: Extracting Base ResNet-50 features\n",
    "\n",
    "   - `classifier()`: ROI feature processing classification head\n",
    "\n",
    "#### **Loss Functions**\n",
    "- **Location**: `data/faster_rcnn/model/losses.py`\n",
    "\n",
    "Specialized loss functions are implemented for:\n",
    "\n",
    "   - The loss of RPN classification (`rpn_loss_cls`)\n",
    "\n",
    "   - Loss from RPN regression (`rpn_loss_regr`)\n",
    "\n",
    "   The final loss of the classifier (`class_loss_cls`, `class_loss_regr`)\n",
    "\n",
    "#### **Training Pipeline**\n",
    "- **Location**: `data/faster_rcnn/train.py`\n",
    "- **Key Features**:\n",
    "  - Two-stage training: first trains RPN, then classifier\n",
    "  - Data augmentation support (horizontal flips, vertical flips, 90° rotations)\n",
    "  - Alternating RPN and classifier training within each iteration\n",
    "- **Training Strategy**:\n",
    "  1. Feed forward through network\n",
    "  2. Generate ROI proposals using RPN\n",
    "  3. Calculate IoU between proposals and ground truth\n",
    "  4. Sample positive and negative examples for classifier\n",
    "  5. Train both RPN and classifier in same iteration\n",
    "\n",
    "#### **Prediction Pipeline**\n",
    "- **Location**: `data/faster_rcnn/predict.py`\n",
    "- **Process**: RPN → ROI extraction → Classification → NMS → Final detections\n",
    "\n",
    "#### **Annotation Validation and Parser** ⭐ (Enhanced)\n",
    "- **Location**: `data/faster_rcnn/model/parser.py`\n",
    "\n",
    "**Important Enhancements:**\n",
    "\n",
    " - Coordinate swapping (x2 < x1 or y2 < y1) is fixed by **automatic coordinate validation**.\n",
    "  \n",
    " - Verifies that every coordinate is inside the boundaries of the image.\n",
    "  \n",
    " - Bounding boxes that are too small or have zero area are eliminated through the process of **\"invalid box filtering.\"**\n",
    "\n",
    "**The handling of missing images:** \n",
    "\n",
    " - elegantly omits missing pictures while providing thorough reporting\n",
    "\n",
    " **Thorough logging:**\n",
    "\n",
    " - gives data on errors, skipped lines, and fixes.\n",
    "\n",
    " **The function of validation:**\n",
    " \n",
    "  ```python\n",
    "  def validate_bbox(x1, y1, x2, y2, width, height):\n",
    "      # Fixes swapped coordinates\n",
    "      # Clamps to image bounds\n",
    "      # Validates minimum size (2×2 pixels)\n",
    "      # Returns (valid, x1, y1, x2, y2)\n",
    "  ```\n",
    "- **Results**: Successfully loads 7,880 valid images with 19 classes from Simpsons dataset\n",
    "\n",
    "#### **Annotation Validation Tool** ⭐ (New)\n",
    "- **Location**: `data/faster_rcnn/validate_annotations.py`\n",
    "- **Purpose**: Standalone script to validate and fix annotation files before training\n",
    "- **Features**:\n",
    "  - Validates bounding box coordinates\n",
    "  - Checks for missing images\n",
    "  - Fixes coordinate errors automatically\n",
    "  - Generates detailed reports\n",
    "- **Usage**:\n",
    "  ```bash\n",
    "  # Validate and create fixed annotation file\n",
    "  python data/faster_rcnn/validate_annotations.py annotation.txt -o annotation_fixed.txt\n",
    "  \n",
    "  # Validate only (report errors without fixing)\n",
    "  python data/faster_rcnn/validate_annotations.py annotation.txt --no-fix\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YOLOv3 - Problem 6: Code Analysis\n",
    "\n",
    "### Important Components of YOLOv3 Implementation:\n",
    "\n",
    "#### **Darknet Backbone**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `darknet_body(x)`\n",
    "- **Implementation**: Custom implementation of Darknet-53 backbone\n",
    "- **Key Features**:\n",
    "  ```python\n",
    "  def darknet_body(x):\n",
    "      x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
    "      x = resblock_body(x, 64, 1)\n",
    "      x = resblock_body(x, 128, 2)\n",
    "      # ... continues with 52 total convolutional layers\n",
    "  ```\n",
    "\n",
    "#### **Multi-Scale Prediction**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `yolo_body()`\n",
    "- **Implementation**: Uses feature maps at 3 different scales (13×13, 26×26, 52×52)\n",
    "- **Key Innovation**: Concatenates features from earlier layers with upsampled features\n",
    "  ```python\n",
    "  # Multi-scale detection heads\n",
    "  route1 = concatenate([(ip), x], axis=-1)\n",
    "  route2 = concatenate([(ip2)], x_small], axis=-1)\n",
    "  ```\n",
    "\n",
    "#### **YOLO Detection Head**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `make_last_layers()`\n",
    "- **Implementation**: Each detection head predicts:\n",
    "  - Bounding box coordinates (4 values)\n",
    "  - Objectness score (1 value)\n",
    "  - Class probabilities (N classes)\n",
    "- **Total outputs**: 3 scales × 3 anchors × (5 + N_classes)\n",
    "\n",
    "#### **Anchor Box System**\n",
    "- **Location**: `data/yolov3/model_data/yolo_anchors.txt`\n",
    "- **Implementation**: Uses pre-defined anchor boxes (9 total: 3 per scale)\n",
    "- **Anchor dimensions**: Optimized for COCO dataset objects\n",
    "\n",
    "#### **Non-Maximum Suppression**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `yolo_eval()`\n",
    "- **Implementation**: Applies IoU-based filtering and class-specific NMS\n",
    "- **Process**: Score threshold → IoU filtering → NMS per class → Final detections\n",
    "\n",
    "#### **Prediction Pipeline**\n",
    "- **Location**: `data/yolov3/yolo.py` - class `YOLO`\n",
    "- **Key Methods**:\n",
    "  - `detect_image()`: Processes individual images\n",
    "  - `detect_video()`: Processes video files\n",
    "  - `letterbox_image()`: Maintains aspect ratio during resizing\n",
    "\n",
    "#### **Training Infrastructure**\n",
    "- **Location**: `data/yolov3/train.py`\n",
    "- **Features**:\n",
    "  - Custom data generators for YOLO format\n",
    "  - Data augmentation (random crops, colors, flips)\n",
    "  - Learning rate scheduling\n",
    "  - Transfer learning support from Darknet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and validating annotations...\n",
      "Parsing annotation files\n",
      "\n",
      "Annotation parsing summary:\n",
      "  Total valid images: 7880\n",
      "  Skipped lines: 0\n",
      "  Fixed bounding boxes: 0\n",
      "  Invalid bounding boxes: 0\n",
      "\n",
      "Training images per class (19 classes):\n",
      "{'abraham_grampa_simpson': 686,\n",
      " 'apu_nahasapeemapetilon': 206,\n",
      " 'bart_simpson': 650,\n",
      " 'bg': 0,\n",
      " 'charles_montgomery_burns': 648,\n",
      " 'chief_wiggum': 208,\n",
      " 'comic_book_guy': 207,\n",
      " 'edna_krabappel': 212,\n",
      " 'homer_simpson': 718,\n",
      " 'kent_brockman': 213,\n",
      " 'krusty_the_clown': 427,\n",
      " 'lisa_simpson': 755,\n",
      " 'marge_simpson': 629,\n",
      " 'milhouse_van_houten': 210,\n",
      " 'moe_szyslak': 403,\n",
      " 'ned_flanders': 675,\n",
      " 'nelson_muntz': 219,\n",
      " 'principal_skinner': 614,\n",
      " 'sideshow_bob': 200}\n",
      "\n",
      "✓ Successfully loaded 7880 images\n",
      "✓ Found 19 classes\n",
      "\n",
      "Top classes by image count:\n",
      "  lisa_simpson: 755 images\n",
      "  homer_simpson: 718 images\n",
      "  abraham_grampa_simpson: 686 images\n",
      "  ned_flanders: 675 images\n",
      "  bart_simpson: 650 images\n",
      "  charles_montgomery_burns: 648 images\n",
      "  marge_simpson: 629 images\n",
      "  principal_skinner: 614 images\n",
      "  krusty_the_clown: 427 images\n",
      "  moe_szyslak: 403 images\n",
      "\n",
      "✓ All annotations validated and ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Example: Validate and test annotation loading\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add paths\n",
    "sys.path.append('data/faster_rcnn')\n",
    "\n",
    "from model.parser import get_data\n",
    "\n",
    "# Load annotations\n",
    "print(\"Loading and validating annotations...\")\n",
    "try:\n",
    "    all_imgs, classes_count, class_mapping = get_data('data/faster_rcnn/annotation_fixed.txt')\n",
    "    \n",
    "    print(f\"\\n✓ Successfully loaded {len(all_imgs)} images\")\n",
    "    print(f\"✓ Found {len(classes_count)} classes\")\n",
    "    print(f\"\\nTop classes by image count:\")\n",
    "    \n",
    "    # Sort by count\n",
    "    sorted_classes = sorted(classes_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    for class_name, count in sorted_classes[:10]:\n",
    "        if class_name != 'bg':\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "    \n",
    "    print(\"\\n✓ All annotations validated and ready for training!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure annotation_fixed.txt exists in data/faster_rcnn/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Comparison\n",
    "\n",
    "| Aspect | Faster R-CNN | YOLOv3 |\n",
    "|--------|-------------|---------|\n",
    "| **Architecture** | Two-stage (RPN + Classifier) | Single-stage |\n",
    "| **Backbone** | ResNet-50 | Darknet-53 |\n",
    "| **Prediction Time** | Slower (multiple steps) | Faster (single pass) |\n",
    "| **Accuracy** | Generally higher | Slightly lower but very competitive |\n",
    "| **Memory Usage** | Higher (ROI storage) | Lower |\n",
    "| **Implementation Complexity** | More complex | Simpler |\n",
    "| **Training** | Two-stage training | End-to-end training |\n",
    "| **Region Proposals** | Explicit RPN | Implicit anchor-based |\n",
    "|\n",
    "\n",
    "**Key Differences:**\n",
    "- **Faster R-CNN**: Region proposal → Feature extraction → Classification cascade\n",
    "- **YOLOv3**: Direct dense prediction with multi-scale feature fusion\n",
    "- **Faster R-CNN**: Better for small objects, more precise localization\n",
    "- **YOLOv3**: Faster inference, better for real-time applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for testing\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Add project paths\n",
    "sys.path.append('data/faster_rcnn')\n",
    "sys.path.append('data/yolov3')\n",
    "\n",
    "print('Dependencies imported successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and validating annotations...\n",
      "Parsing annotation files\n",
      "\n",
      "Annotation parsing summary:\n",
      "  Total valid images: 7880\n",
      "  Skipped lines: 0\n",
      "  Fixed bounding boxes: 0\n",
      "  Invalid bounding boxes: 0\n",
      "\n",
      "Training images per class (19 classes):\n",
      "{'abraham_grampa_simpson': 686,\n",
      " 'apu_nahasapeemapetilon': 206,\n",
      " 'bart_simpson': 650,\n",
      " 'bg': 0,\n",
      " 'charles_montgomery_burns': 648,\n",
      " 'chief_wiggum': 208,\n",
      " 'comic_book_guy': 207,\n",
      " 'edna_krabappel': 212,\n",
      " 'homer_simpson': 718,\n",
      " 'kent_brockman': 213,\n",
      " 'krusty_the_clown': 427,\n",
      " 'lisa_simpson': 755,\n",
      " 'marge_simpson': 629,\n",
      " 'milhouse_van_houten': 210,\n",
      " 'moe_szyslak': 403,\n",
      " 'ned_flanders': 675,\n",
      " 'nelson_muntz': 219,\n",
      " 'principal_skinner': 614,\n",
      " 'sideshow_bob': 200}\n",
      "\n",
      "✓ Successfully loaded 7880 images\n",
      "✓ Found 19 classes\n",
      "\n",
      "Top classes by image count:\n",
      "  lisa_simpson: 755 images\n",
      "  homer_simpson: 718 images\n",
      "  abraham_grampa_simpson: 686 images\n",
      "  ned_flanders: 675 images\n",
      "  bart_simpson: 650 images\n",
      "  charles_montgomery_burns: 648 images\n",
      "  marge_simpson: 629 images\n",
      "  principal_skinner: 614 images\n",
      "  krusty_the_clown: 427 images\n",
      "  moe_szyslak: 403 images\n",
      "\n",
      "✓ All annotations validated and ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Example: Validate and test annotation loading\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add paths\n",
    "sys.path.append('data/faster_rcnn')\n",
    "\n",
    "from model.parser import get_data\n",
    "\n",
    "# Load annotations\n",
    "print(\"Loading and validating annotations...\")\n",
    "try:\n",
    "    all_imgs, classes_count, class_mapping = get_data('data/faster_rcnn/annotation_fixed.txt')\n",
    "    \n",
    "    print(f\"\\n✓ Successfully loaded {len(all_imgs)} images\")\n",
    "    print(f\"✓ Found {len(classes_count)} classes\")\n",
    "    print(f\"\\nTop classes by image count:\")\n",
    "    \n",
    "    # Sort by count\n",
    "    sorted_classes = sorted(classes_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    for class_name, count in sorted_classes[:10]:\n",
    "        if class_name != 'bg':\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "    \n",
    "    print(\"\\n✓ All annotations validated and ready for training!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Make sure annotation_fixed.txt exists in data/faster_rcnn/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup and Configuration\n",
    "\n",
    "### Project Structure:\n",
    "```\n",
    "r-cnn-yolo/\n",
    "├── data/\n",
    "│   ├── faster_rcnn/     # Faster R-CNN implementation\n",
    "│   └── yolov3/          # YOLOv3 implementation\n",
    "├── plots/                # Output results\n",
    "├── src/                  # Source code\n",
    "├── reports/              # Logs and analysis\n",
    "├── main.py               # Main execution script\n",
    "├── object-detection.ipynb # This notebook\n",
    "└── requirements.txt      # Dependencies\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
