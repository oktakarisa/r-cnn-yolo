{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster R-CNN and YOLOv3 Object Detection Assignment\n",
    "\n",
    "This notebook contains the comprehensive analysis and implementation of both Faster R-CNN and YOLOv3 object detection models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Faster R-CNN - Problem 2: Code Analysis\n",
    "\n",
    "### Important Components of Faster R-CNN Implementation:\n",
    "\n",
    "#### **Region Proposal Network (RPN)**\n",
    "- **Location**: `data/faster_rcnn/model/resnet.py` - function `rpn(base_layers, num_anchors)`\n",
    "- **Implementation**: The RPN is implemented as a convolutional layer that slides over the feature map and generates region proposals\n",
    "- **Key Lines**:\n",
    "  ```python\n",
    "  def rpn(base_layers,num_anchors):\n",
    "      x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
    "      x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
    "  ```\n",
    "\n",
    "#### **ROI Pooling Implementation**\n",
    "- **Location**: `data/faster_rcnn/model/RoiPoolingConv.py`\n",
    "- **Implementation**: Custom Keras layer that implements ROI Pooling\n",
    "- **Key Features**: \n",
    "  - Handles both channels_first and channels_last image data formats\n",
    "  - Uses TensorFlow resize operations for efficient pooling\n",
    "  - Converts ROI coordinates to cropped regions and applies max pooling\n",
    "\n",
    "#### **Backbone Network (ResNet)**\n",
    "- **Location**: `data/faster_rcnn/model/resnet.py`\n",
    "- **Implementation**: Uses ResNet-50 as the backbone feature extractor\n",
    "- **Key Functions**:\n",
    "  - `nn_base()`: Base ResNet-50 feature extraction\n",
    "  - `classifier()`: Classification head that processes ROI features\n",
    "\n",
    "#### **Loss Functions**\n",
    "- **Location**: `data/faster_rcnn/model/losses.py`\n",
    "- **Implementation**: Implements specialized loss functions for:\n",
    "  - RPN classification loss (`rpn_loss_cls`)\n",
    "  - RPN regression loss (`rpn_loss_regr`)\n",
    "  - Final classifier loss (`class_loss_cls`, `class_loss_regr`)\n",
    "\n",
    "#### **Training Pipeline**\n",
    "- **Location**: `data/faster_rcnn/train.py`\n",
    "- **Key Features**:\n",
    "  - Two-stage training: first trains RPN, then classifier\n",
    "  - Data augmentation support (horizontal flips, vertical flips, 90° rotations)\n",
    "  - Alternating RPN and classifier training within each iteration\n",
    "- **Training Strategy**:\n",
    "  1. Feed forward through network\n",
    "  2. Generate ROI proposals using RPN\n",
    "  3. Calculate IoU between proposals and ground truth\n",
    "  4. Sample positive and negative examples for classifier\n",
    "  5. Train both RPN and classifier in same iteration\n",
    "\n",
    "#### **Prediction Pipeline**\n",
    "- **Location**: `data/faster_rcnn/predict.py`\n",
    "- **Process**: RPN → ROI extraction → Classification → NMS → Final detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YOLOv3 - Problem 6: Code Analysis\n",
    "\n",
    "### Important Components of YOLOv3 Implementation:\n",
    "\n",
    "#### **Darknet Backbone**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `darknet_body(x)`\n",
    "- **Implementation**: Custom implementation of Darknet-53 backbone\n",
    "- **Key Features**:\n",
    "  ```python\n",
    "  def darknet_body(x):\n",
    "      x = DarknetConv2D_BN_Leaky(32, (3,3))(x)\n",
    "      x = resblock_body(x, 64, 1)\n",
    "      x = resblock_body(x, 128, 2)\n",
    "      # ... continues with 52 total convolutional layers\n",
    "  ```\n",
    "\n",
    "#### **Multi-Scale Prediction**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `yolo_body()`\n",
    "- **Implementation**: Uses feature maps at 3 different scales (13×13, 26×26, 52×52)\n",
    "- **Key Innovation**: Concatenates features from earlier layers with upsampled features\n",
    "  ```python\n",
    "  # Multi-scale detection heads\n",
    "  route1 = concatenate([(ip), x], axis=-1)\n",
    "  route2 = concatenate([(ip2)], x_small], axis=-1)\n",
    "  ```\n",
    "\n",
    "#### **YOLO Detection Head**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `make_last_layers()`\n",
    "- **Implementation**: Each detection head predicts:\n",
    "  - Bounding box coordinates (4 values)\n",
    "  - Objectness score (1 value)\n",
    "  - Class probabilities (N classes)\n",
    "- **Total outputs**: 3 scales × 3 anchors × (5 + N_classes)\n",
    "\n",
    "#### **Anchor Box System**\n",
    "- **Location**: `data/yolov3/model_data/yolo_anchors.txt`\n",
    "- **Implementation**: Uses pre-defined anchor boxes (9 total: 3 per scale)\n",
    "- **Anchor dimensions**: Optimized for COCO dataset objects\n",
    "\n",
    "#### **Non-Maximum Suppression**\n",
    "- **Location**: `data/yolov3/yolo3/model.py` - function `yolo_eval()`\n",
    "- **Implementation**: Applies IoU-based filtering and class-specific NMS\n",
    "- **Process**: Score threshold → IoU filtering → NMS per class → Final detections\n",
    "\n",
    "#### **Prediction Pipeline**\n",
    "- **Location**: `data/yolov3/yolo.py` - class `YOLO`\n",
    "- **Key Methods**:\n",
    "  - `detect_image()`: Processes individual images\n",
    "  - `detect_video()`: Processes video files\n",
    "  - `letterbox_image()`: Maintains aspect ratio during resizing\n",
    "\n",
    "#### **Training Infrastructure**\n",
    "- **Location**: `data/yolov3/train.py`\n",
    "- **Features**:\n",
    "  - Custom data generators for YOLO format\n",
    "  - Data augmentation (random crops, colors, flips)\n",
    "  - Learning rate scheduling\n",
    "  - Transfer learning support from Darknet weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Comparison\n",
    "\n",
    "| Aspect | Faster R-CNN | YOLOv3 |\n",
    "|--------|-------------|---------|\n",
    "| **Architecture** | Two-stage (RPN + Classifier) | Single-stage |\n",
    "| **Backbone** | ResNet-50 | Darknet-53 |\n",
    "| **Prediction Time** | Slower (multiple steps) | Faster (single pass) |\n",
    "| **Accuracy** | Generally higher | Slightly lower but very competitive |\n",
    "| **Memory Usage** | Higher (ROI storage) | Lower |\n",
    "| **Implementation Complexity** | More complex | Simpler |\n",
    "| **Training** | Two-stage training | End-to-end training |\n",
    "| **Region Proposals** | Explicit RPN | Implicit anchor-based |\n",
    "|\n",
    "\n",
    "**Key Differences:**\n",
    "- **Faster R-CNN**: Region proposal → Feature extraction → Classification cascade\n",
    "- **YOLOv3**: Direct dense prediction with multi-scale feature fusion\n",
    "- **Faster R-CNN**: Better for small objects, more precise localization\n",
    "- **YOLOv3**: Faster inference, better for real-time applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for testing\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Add project paths\n",
    "sys.path.append('data/faster_rcnn')\n",
    "sys.path.append('data/yolov3')\n",
    "\n",
    "print('Dependencies imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup and Configuration\n",
    "\n",
    "### Project Structure:\n",
    "```\n",
    "r-cnn-yolo/\n",
    "├── data/\n",
    "│   ├── faster_rcnn/     # Faster R-CNN implementation\n",
    "│   └── yolov3/          # YOLOv3 implementation\n",
    "├── plots/                # Output results\n",
    "├── src/                  # Source code\n",
    "├── reports/              # Logs and analysis\n",
    "├── main.py               # Main execution script\n",
    "├── object-detection.ipynb # This notebook\n",
    "└── requirements.txt      # Dependencies\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
